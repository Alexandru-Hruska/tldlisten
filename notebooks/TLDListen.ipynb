{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60467df3-2fe3-43f1-992e-cb1b54a554d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import gradio as gr\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbd1de4-90a3-41ee-96df-525777323e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
      "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb168c3-4d0d-4e4b-a78c-b214991748c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.26-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.26 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.27-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.29-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.26->llama-index) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (3.11.13)\n",
      "Collecting banks<3.0.0,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.26->llama-index)\n",
      "  Downloading banks-2.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (1.2.18)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.26->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.26->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (2024.12.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.26->llama-index) (1.17.2)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.17-py3-none-any.whl.metadata (902 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.26->llama-index) (1.18.3)\n",
      "Collecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.26->llama-index)\n",
      "  Downloading griffe-1.7.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (3.1.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.26->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.26->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.26->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.26->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (2.3.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.26->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.26->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Collecting platformdirs<5.0.0,>=4.3.7 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.26->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.26->llama-index) (2.1.5)\n",
      "Downloading llama_index-0.12.26-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.27-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_llms_openai-0.3.29-py3-none-any.whl (23 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.1.0-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.17-py3-none-any.whl (253 kB)\n",
      "Downloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n",
      "Downloading llama_cloud_services-0.6.9-py3-none-any.whl (29 kB)\n",
      "Downloading griffe-1.7.1-py3-none-any.whl (129 kB)\n",
      "Downloading platformdirs-4.3.7-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, pypdf, platformdirs, nltk, griffe, greenlet, llama-cloud, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.3.6\n",
      "    Uninstalling platformdirs-4.3.6:\n",
      "      Successfully uninstalled platformdirs-4.3.6\n",
      "Successfully installed banks-2.1.0 dirtyjson-1.0.8 filetype-1.2.0 greenlet-3.1.1 griffe-1.7.1 llama-cloud-0.1.17 llama-cloud-services-0.6.9 llama-index-0.12.26 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.27 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.9 llama-index-llms-openai-0.3.29 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 nltk-3.9.1 platformdirs-4.3.7 pypdf-5.4.0 striprtf-0.0.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb0ba80b-0984-4141-b5af-7e242081e576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyAt\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "embed_model = OpenAIEmbedding()\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d222151d-844e-448e-a1e7-91eca2dd03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_youtube_subtitles(video_url, language='en'):\n",
    "    try:\n",
    "        video_id = video_url.split('v=')[1].split('&')[0]\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
    "        subtitles = '\\n'.join([entry['text'] for entry in transcript])\n",
    "        return subtitles\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd48785-2eb2-41df-ad4f-0847cceb0962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey Al Peter Zion coming to you from\n",
      "Colorado you are getting this message so\n",
      "that you can be informed on April 9\n",
      "we're doing something called question\n",
      "time which is basically when our patreon\n",
      "members can Grill me live about whatever\n",
      "is going on in the world and the primary\n",
      "topic for the event this April 9 is\n",
      "going to be Trump's tariffs which come\n",
      "out the week before and their effect on\n",
      "the American and the global economy\n",
      "moving forward so sign up for our\n",
      "patreon system now join the fun bring\n",
      "your question and we'll see you April 9\n",
      "at noon Eastern if you can't make it\n",
      "that's okay you can get a recording as\n",
      "long as you sign up hey everybody Peter\n",
      "Z here coming to you from the home\n",
      "office apologize for being inside but\n",
      "there's 70 mph winds outside and\n",
      "recording is just not possible uh today\n",
      "is the 17th of March and the news is\n",
      "that American defense secretary Pete\n",
      "hegi just cancelled defense talks with\n",
      "the South Koreans uh he had a really\n",
      "good reason for doing it the South\n",
      "Koreans functionally don't have a\n",
      "government right now uh the former\n",
      "president was impeached currently out on\n",
      "bail which just feels weird linking\n",
      "those words together uh and they haven't\n",
      "had new elections yet so they're really\n",
      "is no one of authority to speak to about\n",
      "really deep strategic issues and there\n",
      "is a very deep strategic issue that\n",
      "needs to be discussed the South Koreans\n",
      "have been looking at what the Trump\n",
      "Administration has been doing with\n",
      "Ukraine and the European allies and even\n",
      "badmouthing uh the Japanese of late and\n",
      "they are coming to the unfortunate\n",
      "conclusion that they are going to have\n",
      "to go It Alone on their defense policy\n",
      "now South Korean military forces have\n",
      "basically been under this American\n",
      "umbrella not just in terms of actual\n",
      "security protection but actually\n",
      "leadership since the Cold War if a war\n",
      "were to break out uh and the North\n",
      "Koreans were to invade South Korea\n",
      "technically the entire South Korean\n",
      "military is under American command even\n",
      "though there's all only about 30 35,000\n",
      "American troops on the peninsula\n",
      "compared to you know 10 times that for\n",
      "South Koreans uh and the South Koreans\n",
      "are one of the few countries that by\n",
      "Donald Trump standards have actually met\n",
      "their defense procurement goals over the\n",
      "course of this last several decades\n",
      "typically spending more than three to\n",
      "three and a half% on defense the entire\n",
      "ton which is kind of the range that\n",
      "Donald Trump until recently said you\n",
      "were supposed to be in uh and at the\n",
      "moment the Trump Administration hasn't\n",
      "really badmouthed the South Koreans in\n",
      "any way like they have the the Germans\n",
      "or the Italians or the Brits or the\n",
      "French or the ukrainians or the ja you\n",
      "know it's a long list you get the point\n",
      "anyway the South Koreans see the reading\n",
      "writing on the wall because they realize\n",
      "they are not what you would call a major\n",
      "Ally the South Koreans are not capable\n",
      "of deploying forces really outside of\n",
      "their theater and so they are definitely\n",
      "in the category of Defense consumer uh\n",
      "regardless of how much of the weight\n",
      "they try to shoulder themselves and\n",
      "their concern is if the Trump\n",
      "Administration just turns his eyes to\n",
      "them that it's just a matter of time\n",
      "before the United States moves on and so\n",
      "they are dusting off the policies from\n",
      "the 60s 7s and 80s that would allow them\n",
      "to do a Sprint to a nuclear weapon uh in\n",
      "a matter of weeks if not days and this\n",
      "has earned them the labor by the United\n",
      "States of sensitive energy country\n",
      "meaning that they are no longer a\n",
      "complete non-c concern when it comes to\n",
      "nuclear proliferation but now something\n",
      "where it's on the radar and that's\n",
      "exactly where they should be and having\n",
      "a discussion at the very top level\n",
      "between the Americans and the South\n",
      "Koreans on what can and would and should\n",
      "happen under all these scenarios is\n",
      "exactly what needs to happen but there's\n",
      "no one to have that conversation with\n",
      "hegf at the moment so delay uh South\n",
      "Korea is hardly the only country that is\n",
      "going to be in this bucket we have a\n",
      "number of other countries who are\n",
      "concerned about what the United States\n",
      "is doing and realize that they need to\n",
      "or coming to the conclusion that they\n",
      "need to come up with their own defense\n",
      "plans and one of the things you have to\n",
      "consider if you haven't had a\n",
      "sufficiently strong conventional Force\n",
      "for a while you know like South Korea\n",
      "has\n",
      "uh building up those conventional forces\n",
      "takes years if not decades the American\n",
      "general staff situation is 50 years and\n",
      "the making aircraft carriers from the\n",
      "point that you decide that you want to\n",
      "do it you go through the design you go\n",
      "through the procurant you go through\n",
      "manufacturing and then finally field\n",
      "testing you know you have a 20 to 25e\n",
      "process considering the speed at which\n",
      "things are unraveling in Europe most\n",
      "countries just don't have that sort of\n",
      "time and so countries who want to\n",
      "actually look out for themselves they\n",
      "can't really rely on conventional forces\n",
      "in the shorter medium term which raises\n",
      "the question of nuclear weapons uh the\n",
      "country that is of course under the\n",
      "greatest pressure is Ukraine and we're\n",
      "supposed to have a conversation very\n",
      "soon between Donald Trump and Vladimir\n",
      "Putin of Russia which will give some\n",
      "indication of just how much Ukrainian\n",
      "territory uh the Americans are willing\n",
      "to sacrifice in order to achieve a peace\n",
      "deal uh but keep in mind that there are\n",
      "multiple nuclear power reactors in\n",
      "Ukraine and Ukraine used to be where all\n",
      "the brains of the Soviet military\n",
      "industrial complex used to be on nuke\n",
      "issues on aircraft issues and on Missile\n",
      "issues so the idea that the ukrainians\n",
      "when Under Pressure can't go nuclear is\n",
      "silly uh next to line of countries in\n",
      "that are already publicly discussing\n",
      "where and how to get the nukes Poland is\n",
      "at the top of that list they've actively\n",
      "asked the United states to deploy\n",
      "nuclear weapons to their soil and that\n",
      "has gotten broadly rebuffed and so now\n",
      "they're discussing what they need to do\n",
      "to get their own uh the road for Poland\n",
      "will be a little bit longer they don't\n",
      "have a native nuclear industry but their\n",
      "manufacturing capacity is robust all\n",
      "they have to do is get the nuclear\n",
      "material and they'd be Off to the Races\n",
      "it would probably take them 3 to n\n",
      "months in order to get a functional\n",
      "weapon not an explodable device they\n",
      "could probably do that in weeks but an\n",
      "actual deliverable weapon probably\n",
      "within 3 to 9\n",
      "months uh the next country country up is\n",
      "the one that I am of course most worried\n",
      "about and that's Germany uh they're\n",
      "having the discussion not should we get\n",
      "nukes but how should we get nukes option\n",
      "one is to partner up with the French and\n",
      "pay money to the French so that the\n",
      "French nuclear detr which has existed\n",
      "since the 50s also covers Germany but at\n",
      "the end of the day the French are the\n",
      "ones who would control that Arsenal and\n",
      "whether or not it should be used or not\n",
      "and so the other option is for the\n",
      "Germans to get as close to the threshold\n",
      "as they possibly CL can get experience\n",
      "in doing the Milling in order to make\n",
      "the WarHeads enriching the uranium and\n",
      "the plutonium and again they have a\n",
      "nuclear industry so they can do this\n",
      "themselves and the idea that the Germans\n",
      "could not put any device into a\n",
      "deliverable weapon system the Germans\n",
      "have been ours manufacturers for a very\n",
      "long time that would not be a challenge\n",
      "uh in between uh look to Sweden and\n",
      "Finland here are two countries that like\n",
      "Ukraine already have an indigenous\n",
      "nuclear civilian Fleet and the swedes\n",
      "like the Germans already have an\n",
      "indigenous robust military system uh for\n",
      "Contracting and manufacturer both of\n",
      "them are openly discussing these options\n",
      "and if they do decide to pull the\n",
      "trigger both of them would have a\n",
      "deliverable weapon in under a month uh\n",
      "rounding out the list in Europe look to\n",
      "Romania uh like the ukrainians they have\n",
      "a nuclear industry uh however their\n",
      "weapon systems are subar and pretty much\n",
      "all imported so they could get a device\n",
      "use it as a fail safe but getting the\n",
      "deliverable system would be a probably a\n",
      "bridge too far at anything less than a\n",
      "12- Monon time frame but it's a lot\n",
      "faster than doubling the size of your\n",
      "army over in East Asia and addition to\n",
      "the crams the two countries to watch\n",
      "obviously are Japan and Taiwan both have\n",
      "a arms industry both have the materials\n",
      "both have plenty of scientists and\n",
      "Engineers who have experience with both\n",
      "you just have to marry the two together\n",
      "it's just a question of how many funds\n",
      "how they decide to put behind it and in\n",
      "the case of Taiwan if they really did\n",
      "feel that the Americans were leaving\n",
      "well they really don't have any option\n",
      "but to get nukes and while the Japanese\n",
      "Navy may be much more powerful with in\n",
      "terms of reach than the Chinese Navy the\n",
      "home islands are within range of a lot\n",
      "of Chinese weapon systems and so if\n",
      "there was a war I don't doubt who would\n",
      "win in the end because the Japanese\n",
      "could choke off the Chinese Mainland but\n",
      "the damage could be extreme and about\n",
      "the only way to mitigate the risk there\n",
      "is deterr in that nukes so there we're\n",
      "talking about eight\n",
      "countries that are likely to pick up\n",
      "nukes in the not too distant future\n",
      "based on how American policy unfolds in\n",
      "the next several weeks to months uh\n",
      "something the Trump Administration is\n",
      "learning is something that every\n",
      "Administration before it has learned\n",
      "including the first Trump Administration\n",
      "is that if you want to write everyone's\n",
      "security policies you have to give them\n",
      "something and during the Cold War and\n",
      "until very recently it was a guns for\n",
      "butter trade the US would protect Global\n",
      "sea Lanes so that anyone could trade\n",
      "with anyone at any time and in exchange\n",
      "the Allies allowed Washington to write\n",
      "their security policies what the Trump\n",
      "Administration is doing is not just\n",
      "breaking that deal but saying that we're\n",
      "not going to protect your trade you are\n",
      "on your own but you're also on your own\n",
      "for defense and that forces all of these\n",
      "countries to take matters into their own\n",
      "hands and if they do that the United\n",
      "States loses the ability to say what can\n",
      "and cannot happen with weapon systems\n",
      "and that leads to a world with a lot\n",
      "more nukes in it and a much much much\n",
      "higher likelihood of actually having a\n",
      "weapons Exchange\n"
     ]
    }
   ],
   "source": [
    "video_url = 'https://www.youtube.com/watch?v=Q7Abm5BBZMM'\n",
    "subtitles = fetch_youtube_subtitles(video_url)\n",
    "print(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67a976e3-af33-403d-a8d2-f0b9e704df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_podcast_index(transcript_text):\n",
    "    \"\"\"Load and process podcast transcript data from provided text.\"\"\"\n",
    "    try:\n",
    "        # Create a Document object from the transcript text\n",
    "        doc = Document(\n",
    "            text=transcript_text,\n",
    "            metadata={\"title\": \"Podcast Transcript\"}\n",
    "        )\n",
    "        \n",
    "        # Create and return index from document with sentence splitter\n",
    "        parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "        return VectorStoreIndex.from_documents(\n",
    "            [doc],\n",
    "            embed_model=embed_model,\n",
    "            transformations=[parser]\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading podcast transcript: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4d8e396-9856-444d-a8d8-82b98cb4fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_podcast(query, transcript_text, chat_history=None):\n",
    "    \"\"\"Query the podcast transcript based on user input.\"\"\"\n",
    "    try:\n",
    "        # Load the index using the provided transcript text\n",
    "        index = load_podcast_index(transcript_text)\n",
    "        if not index:\n",
    "            return \"Error: Could not load podcast transcript data\"\n",
    "        \n",
    "        # Configure retriever for better context\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=index,\n",
    "            similarity_top_k=5,\n",
    "        )\n",
    "        \n",
    "        # Create query engine with custom retriever\n",
    "        query_engine = RetrieverQueryEngine.from_args(retriever=retriever)\n",
    "        \n",
    "        # Query and get response\n",
    "        response = query_engine.query(query)\n",
    "        \n",
    "        # Return formatted response\n",
    "        return str(response)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing query: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c0ffb80-c94d-468d-9a2a-fb66d756a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* Running on public URL: https://fd9b9269a13964cf76.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://fd9b9269a13964cf76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define example questions\n",
    "example_questions = [\n",
    "    [\"What were the main topics discussed?\"],\n",
    "    [\"Give me the key takeaways or insights in dot points\"],\n",
    "    [\"Who were the hosts, guests or organisations in the podcast or video?\"],\n",
    "    [\"Were any significant statistics or data points mentioned?\"],\n",
    "    [\"Can you list any resources or references if mentioned?\"]\n",
    "]\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# TL;DListen: Podcast Transcript Chat\")\n",
    "\n",
    "    # YouTube URL input\n",
    "    youtube_url = gr.Textbox(\n",
    "        label=\"YouTube Video URL\",\n",
    "        placeholder=\"Enter the YouTube video URL here...\"\n",
    "    )\n",
    "\n",
    "    # Instructional text below the YouTube URL input\n",
    "    gr.Markdown(\"*enter the YouTube video URL above before asking questions*\")\n",
    "\n",
    "    # Chat interface\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Conversation\",\n",
    "        height=400,\n",
    "        type='messages'\n",
    "    )\n",
    "\n",
    "    # Query input\n",
    "    msg = gr.Textbox(\n",
    "        label=\"Ask about the podcast\",\n",
    "        placeholder=\"Ask a question about the podcast content...\",\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    # Submit button\n",
    "    submit_btn = gr.Button(\"Send\")\n",
    "\n",
    "    # Example questions\n",
    "    gr.Examples(\n",
    "        examples=example_questions,\n",
    "        inputs=msg,\n",
    "        label=\"Example Questions\"\n",
    "    )\n",
    "\n",
    "    # Chat history state\n",
    "    chat_state = gr.State([])\n",
    "\n",
    "    def respond(youtube_url, message, chat_history):\n",
    "        \"\"\"Process user message and update chat history\"\"\"\n",
    "        if not youtube_url.strip():\n",
    "            return \"Error: Please enter a YouTube video URL.\", chat_history\n",
    "        if not message.strip():\n",
    "            return \"\", chat_history\n",
    "\n",
    "        # Extract subtitles from the provided YouTube URL\n",
    "        subtitles = extract_subtitles(youtube_url)\n",
    "        if \"Error\" in subtitles:\n",
    "            return subtitles, chat_history\n",
    "\n",
    "        # Get response from query engine\n",
    "        bot_response = query_podcast(message, subtitles, chat_history)\n",
    "\n",
    "        # Update chat history\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "\n",
    "        return \"\", chat_history\n",
    "\n",
    "    # Set up interactions\n",
    "    submit_btn.click(\n",
    "        respond,\n",
    "        inputs=[youtube_url, msg, chat_state],\n",
    "        outputs=[msg, chatbot]\n",
    "    )\n",
    "\n",
    "    msg.submit(\n",
    "        respond,\n",
    "        inputs=[youtube_url, msg, chat_state],\n",
    "        outputs=[msg, chatbot]\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"\"\"\n",
    "    ### Tips:\n",
    "    - Ask specific questions about the podcast content\n",
    "    - Try using the example questions provided above\n",
    "    - You can request summaries of specific segments\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49039cdc-7646-452c-8c12-2433c905ff3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
